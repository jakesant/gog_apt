{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, Flatten, Sequential, Conv1d, MaxPool1d, Module, LogSoftmax, NLLLoss, Dropout, MSELoss, Softmax\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_encode = {\n",
    "        \"LAYING\":0,\n",
    "       \"SITTING\":1,\n",
    "       \"STANDING\":2,\n",
    "        \"WALKING\":3,\n",
    "       \"WALKING_DOWNSTAIRS\":4,\n",
    "       \"WALKING_UPSTAIRS\":5\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCI_Dynamic_Dataset(Dataset):\n",
    "    \"\"\"UCI dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, encode=None):\n",
    "\n",
    "        data = pd.read_csv(csv_file)\n",
    "        #print(data.columns )\n",
    "        data['Activity'] = data['Activity'].map(encode)\n",
    "        # self.data = self.data.reshape(5881, 1, 561)\n",
    "        data, _ = [x for _, x in data.groupby(data['Activity'] > 2)]\n",
    "        self.data_y = data['Activity'].values\n",
    "        data = pd.DataFrame(data.drop(['Activity','subject'],axis=1))\n",
    "        self.data_x = np.array(data)\n",
    "        self.root_dir = root_dir\n",
    "        # [batch, channels, features]\n",
    "        self.data_x = self.data_x.reshape(len(self.data_x), 1, 561)\n",
    "        self.data_x  = torch.from_numpy(self.data_x)\n",
    "        self.data_y = self.data_y.astype(int)\n",
    "        self.data_y = torch.from_numpy(self.data_y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # if torch.is_tensor(idx):\n",
    "        #     idx = idx.tolist()\n",
    "        # input = self.data_x.iloc[idx, 1:]\n",
    "        # label = self.data_y.iloc[idx, 1:]\n",
    "        # #\n",
    "        # # sample = {'item': item}\n",
    "        # x = self.data_x[idx]\n",
    "        # y = self.data_y[idx]\n",
    "        return self.data_x[idx], self.data_y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = UCI_Dynamic_Dataset(csv_file='train.csv', root_dir='',encode=activity_encode)\n",
    "valid_data = UCI_Dynamic_Dataset(csv_file='valid.csv', root_dir='',encode=activity_encode)\n",
    "test_data = UCI_Dynamic_Dataset(csv_file='test.csv', root_dir='',encode=activity_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# for inputs, labels in trainloader:\n",
    "#     row = inputs\n",
    "#     cols = labels\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticCNN(Module):\n",
    "    def __init__(self):\n",
    "        super(StaticCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # a\n",
    "            Conv1d(1, 30, kernel_size=tuple([3])), #stride=tuple([1])),\n",
    "            ReLU(),\n",
    "            Conv1d(30, 50, kernel_size=tuple([3])),\n",
    "            ReLU(),\n",
    "            Conv1d(50, 100, kernel_size=tuple([3])),\n",
    "            ReLU(),\n",
    "            # Flatten\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Dropout(0.5),\n",
    "            Linear(55500, 3),\n",
    "            #ReLU(inplace=True),\n",
    "            Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.cnn_layers(x)\n",
    "        # print(x.shape)\n",
    "        # x = x.view(-1, 32*100*561)\n",
    "        #x = Flatten(x)\n",
    "        #print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLLL not MSE because\n",
    "criterion = NLLLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "def train(model, epochs=5):\n",
    "    step = 10\n",
    "    \"\"\"\n",
    "    Function that trains model over the training set, and validates on the validation set\n",
    "    :param model: model to be trained\n",
    "    :param epochs: Times training will be done\n",
    "    :return: trained model\n",
    "    \"\"\"\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "    model.to(device)\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(args.batch_size,  3 * 8 * 8)\n",
    "        target = target.view(args.batch_size, -1)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target[0])\n",
    "    '''\n",
    "    train_losses, valid_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            # print(inputs.shape)\n",
    "            # inputs = inputs.view(32,  32* 1* 561)\n",
    "            # labels = labels.view((32, 3))\n",
    "\n",
    "            log_ps = model(inputs)\n",
    "            # print(\"after\")\n",
    "            #print(log_ps.shape)\n",
    "            #print(labels.max())\n",
    "            #print(labels.min())\n",
    "            #loss_train = criterion(log_ps, labels)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            #loss = criterion(labels,log_ps.view(1, -1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validloader:\n",
    "                    inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "                    log_ps = model(inputs)\n",
    "                    valid_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            train_losses.append(running_loss/len(train_data))\n",
    "            valid_losses.append(valid_loss/len(valid_data))\n",
    "\n",
    "            if (e+1) % step == 0:\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss),\n",
    "                      \"Validation Loss: {:.3f}.. \".format(valid_loss),\n",
    "                      \"Validation Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100..  Training Loss: -121.501..  Validation Loss: -24.863..  Validation Accuracy: 25.212\n",
      "Epoch: 20/100..  Training Loss: -123.260..  Validation Loss: -25.355..  Validation Accuracy: 25.562\n",
      "Epoch: 30/100..  Training Loss: -125.205..  Validation Loss: -25.356..  Validation Accuracy: 25.438\n",
      "Epoch: 40/100..  Training Loss: -125.717..  Validation Loss: -25.628..  Validation Accuracy: 25.750\n",
      "Epoch: 50/100..  Training Loss: -125.639..  Validation Loss: -25.379..  Validation Accuracy: 25.462\n",
      "Epoch: 60/100..  Training Loss: -126.228..  Validation Loss: -25.675..  Validation Accuracy: 25.736\n",
      "Epoch: 70/100..  Training Loss: -126.173..  Validation Loss: -25.464..  Validation Accuracy: 25.500\n",
      "Epoch: 80/100..  Training Loss: -126.489..  Validation Loss: -25.815..  Validation Accuracy: 25.875\n",
      "Epoch: 90/100..  Training Loss: -126.576..  Validation Loss: -25.720..  Validation Accuracy: 25.719\n",
      "Epoch: 100/100..  Training Loss: -126.857..  Validation Loss: -25.571..  Validation Accuracy: 25.618\n"
     ]
    }
   ],
   "source": [
    "model = StaticCNN()\n",
    "train(model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 47.083\n"
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    \"\"\"\n",
    "    Tests model over the testing set\n",
    "    :param model: to be tested\n",
    "    \"\"\"\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    # Turn off gradients for testing, saves memory and computations\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "            log_ps = model(inputs)\n",
    "            test_loss += criterion(log_ps, labels)\n",
    "\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "    print(\"Testing Accuracy: {:.3f}\".format(accuracy))\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
